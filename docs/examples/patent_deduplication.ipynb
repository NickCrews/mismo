{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ibis\n",
    "from ibis import _\n",
    "from ibis.expr.types import (\n",
    "    ArrayValue,\n",
    "    FloatingValue,\n",
    "    IntegerValue,\n",
    "    StringValue,\n",
    "    StructValue,\n",
    ")\n",
    "\n",
    "ibis.options.interactive = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to dedupe the PATSTAT dataset. Every record represents a patent filed,\n",
    "and our task is to determine which one came from the same inventor.\n",
    "The end goal is to add a column called `inventor_id` to each patent.\n",
    "This dataset contains a ground truth label, so we can evaluate how well we did.\n",
    "\n",
    "`Mismo` contains this as an included dataset so it is easy to get started.\n",
    "The returned dataset is an Ibis table, which is a lazy representation of a SQL table.\n",
    "It is similar to a pandas dataframe, but has a few properties that make it much\n",
    "better for the record linkage use case:\n",
    "\n",
    "- Since it is SQL backed, it can handle datasets that are larger than memory, in\n",
    "  the many millions of rows.\n",
    "- Computation is performed by the powerful SQL backend of your choice: Google BigQuery,\n",
    "  Apache Spark, Snowflake, etc. For this demo, we use DuckDB, which is a \n",
    "  state-of-the-art SQL engine based around a columnar data model\n",
    "  (ie oriented towards the bulk operations of record linkage)\n",
    "- Ibis is strongly typed, has a full API, is well-documented, and has good\n",
    "  integration with the rest of the python data science ecosystem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.datasets import load_patents  # noqa: E402\n",
    "\n",
    "patents = load_patents()\n",
    "print(patents.count())\n",
    "patents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.plot import plot_distributions  # noqa: E402\n",
    "\n",
    "plot_distributions(patents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean this up a bit:\n",
    "- clean up whitespace\n",
    "- convert the `coauthors` and `classes` columns to actual arrays (they really represent sets)\n",
    "\n",
    "Each element in `classes` is a 4-character IPC technical code that is like a tag\n",
    "for the patent. Similar patents will have similar tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.clean.strings import norm_whitespace  # noqa: E402\n",
    "\n",
    "\n",
    "def clean_names(names: StringValue) -> StringValue:\n",
    "    names = norm_whitespace(names)\n",
    "    names = names.upper()\n",
    "    # Only want to keep letters, numbers, and spaces\n",
    "    names = names.re_replace(\"[^0-9A-Z ]\", \"\")\n",
    "    # Now have to do whitespace fixup again\n",
    "    names = norm_whitespace(names)\n",
    "    return names\n",
    "\n",
    "\n",
    "def parse_list(s: StringValue) -> ArrayValue:\n",
    "    return s.upper().split(\"**\").map(norm_whitespace).sort()\n",
    "\n",
    "\n",
    "cleaned = patents.select(\n",
    "    \"record_id\",\n",
    "    \"label_true\",\n",
    "    \"name_true\",\n",
    "    \"name\",\n",
    "    name_cleaned=clean_names(_.name),\n",
    "    latitude=_.latitude.nullif(0),\n",
    "    longitude=_.longitude.nullif(0),\n",
    "    coauthors=parse_list(_.coauthors.nullif(\"NONE\")),\n",
    "    classes=parse_list(_.classes),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's add some features. The binned coordinates will be used in the blocking step,\n",
    "so that locations in the same lat/lng bin will be compared to each other.\n",
    "\n",
    "We also generate some features based on the `name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def bin_lat_lon(lat: FloatingValue, lon: FloatingValue) -> StructValue:\n",
    "    \"\"\"Bin a latitude or longitude to 0.1 degree precision, which is ~6 miles.\n",
    "\n",
    "    If both are null, return null.\n",
    "\n",
    "    (52.35, 4.916667 -> (524, 49)\n",
    "    \"\"\"\n",
    "\n",
    "    def _bin_coord(coord: FloatingValue) -> IntegerValue:\n",
    "        return (coord.round(1) * 10).cast(\"int16\").fillna(0)\n",
    "\n",
    "    result = ibis.struct(\n",
    "        {\n",
    "            \"lat_hash\": _bin_coord(lat),\n",
    "            \"lon_hash\": _bin_coord(lon),\n",
    "        }\n",
    "    )\n",
    "    both_null = lat.isnull() & lon.isnull()\n",
    "    return both_null.ifelse(ibis.null(), result)\n",
    "\n",
    "\n",
    "featured = cleaned.mutate(\n",
    "    name_tokens=_.name_cleaned.split(\" \").map(norm_whitespace).sort(),\n",
    "    name_first3=_.name_cleaned[0:3],\n",
    "    coords_hashed=bin_lat_lon(_.latitude, _.longitude),\n",
    ")\n",
    "featured\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now it's time to block! This is where we generate comparisons between records.\n",
    "If we were naive and generated all possible comparisons from N record,\n",
    "you would end up with N^2 comparisons. For our small dataset of ~2000 records\n",
    "we would be able to get away with this, but for datasets much larger than this\n",
    "it would be infeasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.block import BlockingRule, BlockingRules  # noqa: E402\n",
    "\n",
    "rules = BlockingRules(\n",
    "    BlockingRule(\n",
    "        \"Coordinates Close\",\n",
    "        lambda left, right: left.coords_hashed == right.coords_hashed,\n",
    "    ),\n",
    "    BlockingRule(\n",
    "        \"Name First 3\", lambda left, right: left.name_first3 == right.name_first3\n",
    "    ),\n",
    "    BlockingRule(\n",
    "        \"Coauthors Exact\", lambda left, right: left.coauthors == right.coauthors\n",
    "    ),\n",
    "    BlockingRule(\"Classes Exact\", lambda left, right: left.classes == right.classes),\n",
    ")\n",
    "\n",
    "featured = featured.cache()\n",
    "blocked = rules.block(featured, featured, labels=True)\n",
    "blocked = blocked.cache()\n",
    "blocked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of that was the two tables joined together, with a `_l` added\n",
    "to all the columns from the left table, and a `_r` added to all the columns\n",
    "from the right table. In addition, there is a column `blocking_rules` that\n",
    "tells us which blocking rules were used to generate the pair.\n",
    "\n",
    "By blocking, we reduced the number of needed pairs by a large factor.\n",
    "In larger datasets, and with better blocking rules, this would be even more!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo import metrics  # noqa: E402\n",
    "\n",
    "n_comparisons = blocked.count().execute()\n",
    "n_naive = metrics.n_naive_comparisons(featured)\n",
    "reduction_ratio = n_comparisons / n_naive\n",
    "n_naive, n_comparisons, reduction_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we have our candidate pairs generated, let's actually do the\n",
    "comparing of pairs. There are many ways to do this, but one of the most common\n",
    "is to generate a set of Comparison objects, each of which represents a\n",
    "measurement of similarity based on some dimension. Each Comparison is\n",
    "composed of Levels, each of which is a level of agreement:\n",
    "\n",
    "- How well the names match\n",
    "    - exact match\n",
    "    - the first three letters match\n",
    "    - everything else (this is implicit, we don't actually pass this feature)\n",
    "- How well the set of classes match\n",
    "    - exact match\n",
    "    - the [jaccard index](https://en.wikipedia.org/wiki/Jaccard_index) of the sets of classes is above 50%\n",
    "    - everything else\n",
    "- How well the set of coauthors match\n",
    "    - exact match\n",
    "    - the jaccard index of the sets of coauthors is above 50%\n",
    "    - everything else\n",
    "- How well the locations match\n",
    "    - exact match\n",
    "    - within 100 km\n",
    "    - one or both coords are NULL\n",
    "    - everything else "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.compare import (  # noqa: E402\n",
    "    Comparison,\n",
    "    ComparisonLevel,\n",
    "    Comparisons,\n",
    "    distance_km,\n",
    "    exact_level,\n",
    "    jaccard,\n",
    ")\n",
    "\n",
    "name_comparison = Comparison(\n",
    "    name=\"Name\",\n",
    "    levels=[\n",
    "        exact_level(\"name_cleaned\"),\n",
    "        exact_level(\"name_first3\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "classes_comparison = Comparison(\n",
    "    name=\"Classes\",\n",
    "    levels=[\n",
    "        exact_level(\"classes\"),\n",
    "        ComparisonLevel(\n",
    "            name=\"Classes 50% Jaccard\",\n",
    "            condition=lambda table: jaccard(table.classes_l, table.classes_r) >= 0.5,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "coauthors_comparison = Comparison(\n",
    "    name=\"Coauthors\",\n",
    "    levels=[\n",
    "        exact_level(\"coauthors\"),\n",
    "        ComparisonLevel(\n",
    "            name=\"Coauthors 50% Jaccard\",\n",
    "            condition=lambda table: jaccard(table.coauthors_l, table.coauthors_r)\n",
    "            >= 0.5,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "coords_comparison = Comparison(\n",
    "    name=\"Coords\",\n",
    "    levels=[\n",
    "        ComparisonLevel(\n",
    "            name=\"Coords match\",\n",
    "            condition=lambda table: (table.latitude_l == table.latitude_r)\n",
    "            & (table.longitude_l == table.longitude_r),\n",
    "        ),\n",
    "        ComparisonLevel(\n",
    "            name=\"Coords within 100km\",\n",
    "            condition=lambda table: distance_km(\n",
    "                lat1=table.latitude_l,\n",
    "                lon1=table.longitude_l,\n",
    "                lat2=table.latitude_r,\n",
    "                lon2=table.longitude_r,\n",
    "            )\n",
    "            <= 100,\n",
    "        ),\n",
    "        ComparisonLevel(\n",
    "            name=\"One or both coords missing\",\n",
    "            condition=lambda table: table.coords_hashed_l.isnull()\n",
    "            | table.coords_hashed_r.isnull(),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "comparisons = Comparisons(\n",
    "    name_comparison,\n",
    "    classes_comparison,\n",
    "    coauthors_comparison,\n",
    "    coords_comparison,\n",
    ")\n",
    "compared = comparisons.label_pairs(blocked, how=\"name\")\n",
    "compared = compared.cache()\n",
    "compared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above is the blocked table, with a column added for every `Comparison`.\n",
    "The value of each column is the level that the record pair matched at.\n",
    "For example, there is now a \"Name\" column,\n",
    "filled with values like \"exact_name_cleaned\", \"exact_name_first3\", etc.\n",
    "\n",
    "We can plot these features to see how common each level of match is,\n",
    "and which levels are related to each other. You can zoom in by dragging\n",
    "on the bottom minimap plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.compare import plot  # noqa: E402\n",
    "\n",
    "plot(compared, comparisons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to improve our Comparisons. Notice how it is fairly common for\n",
    "Classes, Coords, and Name to match exactly, but Coauthors to have the `else` level?\n",
    "These comparisons are probably true matches, if we inspect them we can see the\n",
    "coauthors of `['REYNOLDS DUDLEY JOHN']` paired with `['REYNOLDS JOHN DUDLEY']`\n",
    "getting classified as `else` because the names don't match exactly. We should probably\n",
    "adjust our Coauthors rule to account for this, but to keep this short we will not here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "compared.filter(\n",
    "    [\n",
    "        _.Classes == \"exact_classes\",\n",
    "        _.Coauthors == \"else\",\n",
    "        _.Coords == \"Coords match\",\n",
    "        _.Name == \"exact_name_cleaned\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our features, we can use the Fellegi-Sunter model to train weights\n",
    "for each of these features. This is a probabilistic model that is based on the concept\n",
    "of odds. When you see an exact match on name, that increases the odds of a match\n",
    "by some amount, maybe 50x. When you see a non-match on name, that decreases the odds\n",
    "of a match by some amount, maybe 0.1x. We can either train this from labeled data,\n",
    "or we can use unlabeled data using an algorithm called \"Expectation Maximization\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.compare.fs import train_comparisons  # noqa: E402\n",
    "\n",
    "weights = train_comparisons(comparisons, featured, featured, max_pairs=10_000, seed=42)\n",
    "weights.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the weights to score the record pairs, findng the odds for each\n",
    "Comparison, and then combining them into an overall odds for the record pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scored = weights.score(compared)\n",
    "scored = scored.cache()\n",
    "scored\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the different combinations of comparisons that we found, and see which ones\n",
    "led to the best match, and which ones to the worst.\n",
    "\n",
    "Unsurprisingly, the exact match levels have the highest odds, and the\n",
    "ELSE levels have the lowest. The other levels are somewhere in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "comparison_columns = [comp.name for comp in comparisons]\n",
    "vector_counts = scored.group_by(comparison_columns).agg(\n",
    "    n_pairs=_.count(),\n",
    "    odds=_.odds.arbitrary(),\n",
    ")\n",
    "best = vector_counts.order_by(_.odds.desc()).head(5)\n",
    "worst = vector_counts.order_by(_.odds.asc()).head(5)\n",
    "best, worst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot all of these to try to find a threshold for what to count as a match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import altair as alt  # noqa: E402\n",
    "\n",
    "alt.Chart(vector_counts.execute()).mark_bar().encode(\n",
    "    x=\"odds\",\n",
    "    y=alt.Y(\n",
    "        \"n_pairs\",\n",
    "        scale=alt.Scale(type=\"log\"),\n",
    "    ),\n",
    "    color=\"odds\",\n",
    "    tooltip=[\n",
    "        \"odds\",\n",
    "        \"Name\",\n",
    "        \"Classes\",\n",
    "        \"Coauthors\",\n",
    "        \"Coords\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like an odds of 1500 seems to separate the comparisons into two nice clusters.\n",
    "If I hover over the above chart, I can see that pretty much all the ELSE comparisons\n",
    "are in the low cluster, and all the SAME comparisons are in the high cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "odds_threshold = 1500\n",
    "(scored.odds >= odds_threshold).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be really picky and only take the most likely matches as true matches, and\n",
    "then perform connected components to label each patent with its inventor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mismo.cluster import connected_components  # noqa: E402\n",
    "\n",
    "links = scored[_.odds >= odds_threshold]\n",
    "links = links.cache()\n",
    "print(links.count())\n",
    "labels = connected_components(links, nodes=featured.record_id)\n",
    "print(labels.count())\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate how good our labeling is. Mismo wraps all of the evaluation\n",
    "metrics from sklearn, so we can use them with Ibis Tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "labels_true = patents.select(\"record_id\", label=_.label_true)\n",
    "labels_pred = labels.select(\"record_id\", label=_.component)\n",
    "metrics.adjusted_rand_score(labels_true, labels_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "metrics.homogeneity_score(labels_true, labels_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high homogeneity means we have a high precision, and don't have a lot of false-links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.6)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "metrics.completeness_score(labels_true, labels_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low completeness score means we have low recall, and are missing a lot of true-links"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e78e9de428406fb70aaa5b059884c560deb0c475ef30202c8dca5fdfb55b8986"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mismo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
